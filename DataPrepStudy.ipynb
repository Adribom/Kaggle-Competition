{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data\n",
    "\n",
    "![ML Pathway1](https://github.com/Adribom/Kaggle-Competition/assets/50799373/ac672943-c1dc-41e6-8890-66a0b5dcf2fe)\n",
    "\n",
    "---\n",
    "\n",
    "## Loading the data with only Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check how many lines in train.csv\n",
    "# with open('train.csv') as file:\n",
    "#     n_rows = len(file.readlines())\n",
    "# n_rows"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file has 55423857 lines. Only to count the number of lines, it took 5m 23.3s!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 120 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['key', 'fare_amount', 'pickup_datetime', 'pickup_longitude',\n",
       "       'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n",
       "       'passenger_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train_df_chunk1 = pd.read_csv('train.csv', nrows=100)\n",
    "train_df_chunk1.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features\n",
    "- **pickup_datetime** - timestamp value indicating when the taxi ride started.\n",
    "- **pickup_longitude** - float for longitude coordinate of where the taxi ride started.\n",
    "- **pickup_latitude** - float for latitude coordinate of where the taxi ride started.\n",
    "- **dropoff_longitude** - float for longitude coordinate of where the taxi ride ended.\n",
    "- **dropoff_latitude** - float for latitude coordinate of where the taxi ride ended.\n",
    "- **passenger_count** - integer indicating the number of passengers in the taxi ride."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-06-15 17:26:21.0000001</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2009-06-15 17:26:21 UTC</td>\n",
       "      <td>-73.844311</td>\n",
       "      <td>40.721319</td>\n",
       "      <td>-73.841610</td>\n",
       "      <td>40.712278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-05 16:52:16.0000002</td>\n",
       "      <td>16.9</td>\n",
       "      <td>2010-01-05 16:52:16 UTC</td>\n",
       "      <td>-74.016048</td>\n",
       "      <td>40.711303</td>\n",
       "      <td>-73.979268</td>\n",
       "      <td>40.782004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-08-18 00:35:00.00000049</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2011-08-18 00:35:00 UTC</td>\n",
       "      <td>-73.982738</td>\n",
       "      <td>40.761270</td>\n",
       "      <td>-73.991242</td>\n",
       "      <td>40.750562</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-04-21 04:30:42.0000001</td>\n",
       "      <td>7.7</td>\n",
       "      <td>2012-04-21 04:30:42 UTC</td>\n",
       "      <td>-73.987130</td>\n",
       "      <td>40.733143</td>\n",
       "      <td>-73.991567</td>\n",
       "      <td>40.758092</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-03-09 07:51:00.000000135</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2010-03-09 07:51:00 UTC</td>\n",
       "      <td>-73.968095</td>\n",
       "      <td>40.768008</td>\n",
       "      <td>-73.956655</td>\n",
       "      <td>40.783762</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             key  fare_amount          pickup_datetime  \\\n",
       "0    2009-06-15 17:26:21.0000001          4.5  2009-06-15 17:26:21 UTC   \n",
       "1    2010-01-05 16:52:16.0000002         16.9  2010-01-05 16:52:16 UTC   \n",
       "2   2011-08-18 00:35:00.00000049          5.7  2011-08-18 00:35:00 UTC   \n",
       "3    2012-04-21 04:30:42.0000001          7.7  2012-04-21 04:30:42 UTC   \n",
       "4  2010-03-09 07:51:00.000000135          5.3  2010-03-09 07:51:00 UTC   \n",
       "\n",
       "   pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  \\\n",
       "0        -73.844311        40.721319         -73.841610         40.712278   \n",
       "1        -74.016048        40.711303         -73.979268         40.782004   \n",
       "2        -73.982738        40.761270         -73.991242         40.750562   \n",
       "3        -73.987130        40.733143         -73.991567         40.758092   \n",
       "4        -73.968095        40.768008         -73.956655         40.783762   \n",
       "\n",
       "   passenger_count  \n",
       "0                1  \n",
       "1                1  \n",
       "2                2  \n",
       "3                1  \n",
       "4                1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_chunk1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   key                100 non-null    object \n",
      " 1   fare_amount        100 non-null    float64\n",
      " 2   pickup_datetime    100 non-null    object \n",
      " 3   pickup_longitude   100 non-null    float64\n",
      " 4   pickup_latitude    100 non-null    float64\n",
      " 5   dropoff_longitude  100 non-null    float64\n",
      " 6   dropoff_latitude   100 non-null    float64\n",
      " 7   passenger_count    100 non-null    int64  \n",
      "dtypes: float64(5), int64(1), object(2)\n",
      "memory usage: 6.4+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df_chunk1.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns that have dtype64 doesn't need such precision. We can then resuce de quantity of memory used. As an example:\n",
    "\n",
    "- int8 can store integers from -128 to 127.\n",
    "- int16 can store integers from -32768 to 32767.\n",
    "- int64 can store integers from -9223372036854775808 to 9223372036854775807.\n",
    "\n",
    "\n",
    "In this case, we can do the following transformations, depending on the feature comlumn:\n",
    "- float64 --> float32 | float16\n",
    "- int64 --> int8\n",
    "- object --> string[pyarrow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversão de valores para cada coluna\n",
    "new_dtype = {'fare_amount' : 'float16',\n",
    "             'pickup_datetime' : 'string[pyarrow]', \n",
    "             'pickup_longitude' : 'float32', \n",
    "             'pickup_latitude' : 'float32',\n",
    "             'dropoff_longitude' : 'float32', \n",
    "             'dropoff_latitude' : 'float32', \n",
    "             'passenger_count' : 'int8'} "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "furthermore, the column 'key' isn't necessary for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fare_amount',\n",
       " 'pickup_datetime',\n",
       " 'pickup_longitude',\n",
       " 'pickup_latitude',\n",
       " 'dropoff_longitude',\n",
       " 'dropoff_latitude',\n",
       " 'passenger_count']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lista das colunas que serão utilizadas no treino\n",
    "req_cols = train_df_chunk1.columns.tolist()\n",
    "req_cols.pop(0)\n",
    "req_cols"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the files and read them in chunks can also help optimze the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>2009-06-15 17:26:21 UTC</td>\n",
       "      <td>-73.844315</td>\n",
       "      <td>40.721317</td>\n",
       "      <td>-73.841614</td>\n",
       "      <td>40.712276</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.906250</td>\n",
       "      <td>2010-01-05 16:52:16 UTC</td>\n",
       "      <td>-74.016045</td>\n",
       "      <td>40.711304</td>\n",
       "      <td>-73.979271</td>\n",
       "      <td>40.782005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.699219</td>\n",
       "      <td>2011-08-18 00:35:00 UTC</td>\n",
       "      <td>-73.982735</td>\n",
       "      <td>40.761269</td>\n",
       "      <td>-73.991241</td>\n",
       "      <td>40.750561</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.699219</td>\n",
       "      <td>2012-04-21 04:30:42 UTC</td>\n",
       "      <td>-73.987129</td>\n",
       "      <td>40.733143</td>\n",
       "      <td>-73.991570</td>\n",
       "      <td>40.758091</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.300781</td>\n",
       "      <td>2010-03-09 07:51:00 UTC</td>\n",
       "      <td>-73.968094</td>\n",
       "      <td>40.768009</td>\n",
       "      <td>-73.956657</td>\n",
       "      <td>40.783764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fare_amount          pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
       "0     4.500000  2009-06-15 17:26:21 UTC        -73.844315        40.721317   \n",
       "1    16.906250  2010-01-05 16:52:16 UTC        -74.016045        40.711304   \n",
       "2     5.699219  2011-08-18 00:35:00 UTC        -73.982735        40.761269   \n",
       "3     7.699219  2012-04-21 04:30:42 UTC        -73.987129        40.733143   \n",
       "4     5.300781  2010-03-09 07:51:00 UTC        -73.968094        40.768009   \n",
       "\n",
       "   dropoff_longitude  dropoff_latitude  passenger_count  \n",
       "0         -73.841614         40.712276                1  \n",
       "1         -73.979271         40.782005                1  \n",
       "2         -73.991241         40.750561                2  \n",
       "3         -73.991570         40.758091                1  \n",
       "4         -73.956657         40.783764                1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nrows=1000\n",
    "train_df_chunk2 = pd.read_csv('train.csv', usecols=req_cols, dtype=new_dtype, nrows=1000)\n",
    "train_df_chunk2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index                  128\n",
       "key                  84695\n",
       "fare_amount           8000\n",
       "pickup_datetime      80000\n",
       "pickup_longitude      8000\n",
       "pickup_latitude       8000\n",
       "dropoff_longitude     8000\n",
       "dropoff_latitude      8000\n",
       "passenger_count       8000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_chunk1.memory_usage(deep= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index                  128\n",
       "fare_amount           2000\n",
       "pickup_datetime      27000\n",
       "pickup_longitude      4000\n",
       "pickup_latitude       4000\n",
       "dropoff_longitude     4000\n",
       "dropoff_latitude      4000\n",
       "passenger_count       1000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_chunk2.memory_usage(deep= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_tp = pd.read_csv('train.csv', usecols=req_cols, dtype=new_dtype, iterator=True, chunksize=10000)\n",
    "train_df = pd.concat(train_tp, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>2009-06-15 17:26:21 UTC</td>\n",
       "      <td>-73.844315</td>\n",
       "      <td>40.721317</td>\n",
       "      <td>-73.841614</td>\n",
       "      <td>40.712276</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.906250</td>\n",
       "      <td>2010-01-05 16:52:16 UTC</td>\n",
       "      <td>-74.016045</td>\n",
       "      <td>40.711304</td>\n",
       "      <td>-73.979271</td>\n",
       "      <td>40.782005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.699219</td>\n",
       "      <td>2011-08-18 00:35:00 UTC</td>\n",
       "      <td>-73.982735</td>\n",
       "      <td>40.761269</td>\n",
       "      <td>-73.991241</td>\n",
       "      <td>40.750561</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.699219</td>\n",
       "      <td>2012-04-21 04:30:42 UTC</td>\n",
       "      <td>-73.987129</td>\n",
       "      <td>40.733143</td>\n",
       "      <td>-73.991570</td>\n",
       "      <td>40.758091</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.300781</td>\n",
       "      <td>2010-03-09 07:51:00 UTC</td>\n",
       "      <td>-73.968094</td>\n",
       "      <td>40.768009</td>\n",
       "      <td>-73.956657</td>\n",
       "      <td>40.783764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55423851</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>2014-03-15 03:28:00 UTC</td>\n",
       "      <td>-74.005272</td>\n",
       "      <td>40.740028</td>\n",
       "      <td>-73.963280</td>\n",
       "      <td>40.762554</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55423852</th>\n",
       "      <td>4.199219</td>\n",
       "      <td>2009-03-24 20:46:20 UTC</td>\n",
       "      <td>-73.957787</td>\n",
       "      <td>40.765530</td>\n",
       "      <td>-73.951637</td>\n",
       "      <td>40.773960</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55423853</th>\n",
       "      <td>14.101562</td>\n",
       "      <td>2011-04-02 22:04:24 UTC</td>\n",
       "      <td>-73.970505</td>\n",
       "      <td>40.752323</td>\n",
       "      <td>-73.960541</td>\n",
       "      <td>40.797340</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55423854</th>\n",
       "      <td>28.906250</td>\n",
       "      <td>2011-10-26 05:57:51 UTC</td>\n",
       "      <td>-73.980904</td>\n",
       "      <td>40.764629</td>\n",
       "      <td>-73.870605</td>\n",
       "      <td>40.773964</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55423855</th>\n",
       "      <td>7.500000</td>\n",
       "      <td>2014-12-12 11:33:00 UTC</td>\n",
       "      <td>-73.969719</td>\n",
       "      <td>40.797668</td>\n",
       "      <td>-73.970886</td>\n",
       "      <td>40.783314</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55423480 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          fare_amount          pickup_datetime  pickup_longitude  \\\n",
       "0            4.500000  2009-06-15 17:26:21 UTC        -73.844315   \n",
       "1           16.906250  2010-01-05 16:52:16 UTC        -74.016045   \n",
       "2            5.699219  2011-08-18 00:35:00 UTC        -73.982735   \n",
       "3            7.699219  2012-04-21 04:30:42 UTC        -73.987129   \n",
       "4            5.300781  2010-03-09 07:51:00 UTC        -73.968094   \n",
       "...               ...                      ...               ...   \n",
       "55423851    14.000000  2014-03-15 03:28:00 UTC        -74.005272   \n",
       "55423852     4.199219  2009-03-24 20:46:20 UTC        -73.957787   \n",
       "55423853    14.101562  2011-04-02 22:04:24 UTC        -73.970505   \n",
       "55423854    28.906250  2011-10-26 05:57:51 UTC        -73.980904   \n",
       "55423855     7.500000  2014-12-12 11:33:00 UTC        -73.969719   \n",
       "\n",
       "          pickup_latitude  dropoff_longitude  dropoff_latitude  \\\n",
       "0               40.721317         -73.841614         40.712276   \n",
       "1               40.711304         -73.979271         40.782005   \n",
       "2               40.761269         -73.991241         40.750561   \n",
       "3               40.733143         -73.991570         40.758091   \n",
       "4               40.768009         -73.956657         40.783764   \n",
       "...                   ...                ...               ...   \n",
       "55423851        40.740028         -73.963280         40.762554   \n",
       "55423852        40.765530         -73.951637         40.773960   \n",
       "55423853        40.752323         -73.960541         40.797340   \n",
       "55423854        40.764629         -73.870605         40.773964   \n",
       "55423855        40.797668         -73.970886         40.783314   \n",
       "\n",
       "          passenger_count  \n",
       "0                       1  \n",
       "1                       1  \n",
       "2                       2  \n",
       "3                       1  \n",
       "4                       1  \n",
       "...                   ...  \n",
       "55423851                1  \n",
       "55423852                1  \n",
       "55423853                1  \n",
       "55423854                1  \n",
       "55423855                1  \n",
       "\n",
       "[55423480 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remover NaN\n",
    "train_df.dropna(how = 'any', axis = 'rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On my computer, cant even finish the operation without running out of memory\n",
    "\n",
    "def travel_distance(latitude_start, longitude_start, latitude_finish, longitude_finish):\n",
    "    return np.sqrt(np.abs(latitude_finish-latitude_start)**2 + np.abs(longitude_finish-longitude_start)**2)\n",
    "\n",
    "train_df['travel_distance'] = np.vectorize(travel_distance)(train_df['pickup_latitude'], train_df['pickup_longitude'], \n",
    "                                                            train_df['dropoff_latitude'], train_df['dropoff_longitude'])\n",
    "\n",
    "train_df.sort_values(travel_distance)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask (Parallel processing)\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simply using Dask instead of Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31.2 ms\n",
      "Wall time: 257 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = dd.read_csv('train.csv', usecols=req_cols, dtype=new_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>2009-06-15 17:26:21 UTC</td>\n",
       "      <td>-73.844315</td>\n",
       "      <td>40.721317</td>\n",
       "      <td>-73.841614</td>\n",
       "      <td>40.712276</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.906250</td>\n",
       "      <td>2010-01-05 16:52:16 UTC</td>\n",
       "      <td>-74.016045</td>\n",
       "      <td>40.711304</td>\n",
       "      <td>-73.979271</td>\n",
       "      <td>40.782005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.699219</td>\n",
       "      <td>2011-08-18 00:35:00 UTC</td>\n",
       "      <td>-73.982735</td>\n",
       "      <td>40.761269</td>\n",
       "      <td>-73.991241</td>\n",
       "      <td>40.750561</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.699219</td>\n",
       "      <td>2012-04-21 04:30:42 UTC</td>\n",
       "      <td>-73.987129</td>\n",
       "      <td>40.733143</td>\n",
       "      <td>-73.991570</td>\n",
       "      <td>40.758091</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.300781</td>\n",
       "      <td>2010-03-09 07:51:00 UTC</td>\n",
       "      <td>-73.968094</td>\n",
       "      <td>40.768009</td>\n",
       "      <td>-73.956657</td>\n",
       "      <td>40.783764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fare_amount          pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
       "0     4.500000  2009-06-15 17:26:21 UTC        -73.844315        40.721317   \n",
       "1    16.906250  2010-01-05 16:52:16 UTC        -74.016045        40.711304   \n",
       "2     5.699219  2011-08-18 00:35:00 UTC        -73.982735        40.761269   \n",
       "3     7.699219  2012-04-21 04:30:42 UTC        -73.987129        40.733143   \n",
       "4     5.300781  2010-03-09 07:51:00 UTC        -73.968094        40.768009   \n",
       "\n",
       "   dropoff_longitude  dropoff_latitude  passenger_count  \n",
       "0         -73.841614         40.712276                1  \n",
       "1         -73.979271         40.782005                1  \n",
       "2         -73.991241         40.750561                2  \n",
       "3         -73.991570         40.758091                1  \n",
       "4         -73.956657         40.783764                1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fare_amount            0\n",
       "pickup_datetime        0\n",
       "pickup_longitude       0\n",
       "pickup_latitude        0\n",
       "dropoff_longitude    376\n",
       "dropoff_latitude     376\n",
       "passenger_count        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().compute()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until this step, the operations have been very fast. Thats because dask only does the real computation when we specify it with .compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 51s\n",
      "Wall time: 1min 37s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>2009-06-15 17:26:21 UTC</td>\n",
       "      <td>-73.844315</td>\n",
       "      <td>40.721317</td>\n",
       "      <td>-73.841614</td>\n",
       "      <td>40.712276</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.906250</td>\n",
       "      <td>2010-01-05 16:52:16 UTC</td>\n",
       "      <td>-74.016045</td>\n",
       "      <td>40.711304</td>\n",
       "      <td>-73.979271</td>\n",
       "      <td>40.782005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.699219</td>\n",
       "      <td>2011-08-18 00:35:00 UTC</td>\n",
       "      <td>-73.982735</td>\n",
       "      <td>40.761269</td>\n",
       "      <td>-73.991241</td>\n",
       "      <td>40.750561</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.699219</td>\n",
       "      <td>2012-04-21 04:30:42 UTC</td>\n",
       "      <td>-73.987129</td>\n",
       "      <td>40.733143</td>\n",
       "      <td>-73.991570</td>\n",
       "      <td>40.758091</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.300781</td>\n",
       "      <td>2010-03-09 07:51:00 UTC</td>\n",
       "      <td>-73.968094</td>\n",
       "      <td>40.768009</td>\n",
       "      <td>-73.956657</td>\n",
       "      <td>40.783764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622599</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>2014-03-15 03:28:00 UTC</td>\n",
       "      <td>-74.005272</td>\n",
       "      <td>40.740028</td>\n",
       "      <td>-73.963280</td>\n",
       "      <td>40.762554</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622600</th>\n",
       "      <td>4.199219</td>\n",
       "      <td>2009-03-24 20:46:20 UTC</td>\n",
       "      <td>-73.957787</td>\n",
       "      <td>40.765530</td>\n",
       "      <td>-73.951637</td>\n",
       "      <td>40.773960</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622601</th>\n",
       "      <td>14.101562</td>\n",
       "      <td>2011-04-02 22:04:24 UTC</td>\n",
       "      <td>-73.970505</td>\n",
       "      <td>40.752323</td>\n",
       "      <td>-73.960541</td>\n",
       "      <td>40.797340</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622602</th>\n",
       "      <td>28.906250</td>\n",
       "      <td>2011-10-26 05:57:51 UTC</td>\n",
       "      <td>-73.980904</td>\n",
       "      <td>40.764629</td>\n",
       "      <td>-73.870605</td>\n",
       "      <td>40.773964</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622603</th>\n",
       "      <td>7.500000</td>\n",
       "      <td>2014-12-12 11:33:00 UTC</td>\n",
       "      <td>-73.969719</td>\n",
       "      <td>40.797668</td>\n",
       "      <td>-73.970886</td>\n",
       "      <td>40.783314</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55423480 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fare_amount          pickup_datetime  pickup_longitude  \\\n",
       "0          4.500000  2009-06-15 17:26:21 UTC        -73.844315   \n",
       "1         16.906250  2010-01-05 16:52:16 UTC        -74.016045   \n",
       "2          5.699219  2011-08-18 00:35:00 UTC        -73.982735   \n",
       "3          7.699219  2012-04-21 04:30:42 UTC        -73.987129   \n",
       "4          5.300781  2010-03-09 07:51:00 UTC        -73.968094   \n",
       "...             ...                      ...               ...   \n",
       "622599    14.000000  2014-03-15 03:28:00 UTC        -74.005272   \n",
       "622600     4.199219  2009-03-24 20:46:20 UTC        -73.957787   \n",
       "622601    14.101562  2011-04-02 22:04:24 UTC        -73.970505   \n",
       "622602    28.906250  2011-10-26 05:57:51 UTC        -73.980904   \n",
       "622603     7.500000  2014-12-12 11:33:00 UTC        -73.969719   \n",
       "\n",
       "        pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \n",
       "0             40.721317         -73.841614         40.712276                1  \n",
       "1             40.711304         -73.979271         40.782005                1  \n",
       "2             40.761269         -73.991241         40.750561                2  \n",
       "3             40.733143         -73.991570         40.758091                1  \n",
       "4             40.768009         -73.956657         40.783764                1  \n",
       "...                 ...                ...               ...              ...  \n",
       "622599        40.740028         -73.963280         40.762554                1  \n",
       "622600        40.765530         -73.951637         40.773960                1  \n",
       "622601        40.752323         -73.960541         40.797340                1  \n",
       "622602        40.764629         -73.870605         40.773964                1  \n",
       "622603        40.797668         -73.970886         40.783314                1  \n",
       "\n",
       "[55423480 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df.dropna(how='any').compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtravel_distance\u001b[39m(latitude_start, longitude_start, latitude_finish, longitude_finish):\n\u001b[0;32m      2\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39msqrt(np\u001b[39m.\u001b[39mabs(latitude_finish\u001b[39m-\u001b[39mlatitude_start)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39mabs(longitude_finish\u001b[39m-\u001b[39mlongitude_start)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mtravel_distance\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mvectorize(travel_distance)(df[\u001b[39m'\u001b[39;49m\u001b[39mpickup_latitude\u001b[39;49m\u001b[39m'\u001b[39;49m], df[\u001b[39m'\u001b[39;49m\u001b[39mpickup_longitude\u001b[39;49m\u001b[39m'\u001b[39;49m], \n\u001b[0;32m      5\u001b[0m                                                         df[\u001b[39m'\u001b[39;49m\u001b[39mdropoff_latitude\u001b[39;49m\u001b[39m'\u001b[39;49m], df[\u001b[39m'\u001b[39;49m\u001b[39mdropoff_longitude\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\numpy\\lib\\function_base.py:2328\u001b[0m, in \u001b[0;36mvectorize.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2325\u001b[0m     vargs \u001b[39m=\u001b[39m [args[_i] \u001b[39mfor\u001b[39;00m _i \u001b[39min\u001b[39;00m inds]\n\u001b[0;32m   2326\u001b[0m     vargs\u001b[39m.\u001b[39mextend([kwargs[_n] \u001b[39mfor\u001b[39;00m _n \u001b[39min\u001b[39;00m names])\n\u001b[1;32m-> 2328\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_vectorize_call(func\u001b[39m=\u001b[39;49mfunc, args\u001b[39m=\u001b[39;49mvargs)\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\numpy\\lib\\function_base.py:2409\u001b[0m, in \u001b[0;36mvectorize._vectorize_call\u001b[1;34m(self, func, args)\u001b[0m\n\u001b[0;32m   2406\u001b[0m ufunc, otypes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_ufunc_and_otypes(func\u001b[39m=\u001b[39mfunc, args\u001b[39m=\u001b[39margs)\n\u001b[0;32m   2408\u001b[0m \u001b[39m# Convert args to object arrays first\u001b[39;00m\n\u001b[1;32m-> 2409\u001b[0m inputs \u001b[39m=\u001b[39m [asanyarray(a, dtype\u001b[39m=\u001b[39m\u001b[39mobject\u001b[39m) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m args]\n\u001b[0;32m   2411\u001b[0m outputs \u001b[39m=\u001b[39m ufunc(\u001b[39m*\u001b[39minputs)\n\u001b[0;32m   2413\u001b[0m \u001b[39mif\u001b[39;00m ufunc\u001b[39m.\u001b[39mnout \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\numpy\\lib\\function_base.py:2409\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2406\u001b[0m ufunc, otypes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_ufunc_and_otypes(func\u001b[39m=\u001b[39mfunc, args\u001b[39m=\u001b[39margs)\n\u001b[0;32m   2408\u001b[0m \u001b[39m# Convert args to object arrays first\u001b[39;00m\n\u001b[1;32m-> 2409\u001b[0m inputs \u001b[39m=\u001b[39m [asanyarray(a, dtype\u001b[39m=\u001b[39;49m\u001b[39mobject\u001b[39;49m) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m args]\n\u001b[0;32m   2411\u001b[0m outputs \u001b[39m=\u001b[39m ufunc(\u001b[39m*\u001b[39minputs)\n\u001b[0;32m   2413\u001b[0m \u001b[39mif\u001b[39;00m ufunc\u001b[39m.\u001b[39mnout \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\dask\\dataframe\\core.py:590\u001b[0m, in \u001b[0;36m_Frame.__array__\u001b[1;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 590\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_computed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute()\n\u001b[0;32m    591\u001b[0m     x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_computed)\n\u001b[0;32m    592\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\dask\\base.py:314\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    291\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \n\u001b[0;32m    293\u001b[0m \u001b[39m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[39m    dask.base.compute\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 314\u001b[0m     (result,) \u001b[39m=\u001b[39m compute(\u001b[39mself\u001b[39m, traverse\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    315\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\dask\\base.py:599\u001b[0m, in \u001b[0;36mcompute\u001b[1;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[0;32m    596\u001b[0m     keys\u001b[39m.\u001b[39mappend(x\u001b[39m.\u001b[39m__dask_keys__())\n\u001b[0;32m    597\u001b[0m     postcomputes\u001b[39m.\u001b[39mappend(x\u001b[39m.\u001b[39m__dask_postcompute__())\n\u001b[1;32m--> 599\u001b[0m results \u001b[39m=\u001b[39m schedule(dsk, keys, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    600\u001b[0m \u001b[39mreturn\u001b[39;00m repack([f(r, \u001b[39m*\u001b[39ma) \u001b[39mfor\u001b[39;00m r, (f, a) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\dask\\threaded.py:89\u001b[0m, in \u001b[0;36mget\u001b[1;34m(dsk, keys, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(pool, multiprocessing\u001b[39m.\u001b[39mpool\u001b[39m.\u001b[39mPool):\n\u001b[0;32m     87\u001b[0m         pool \u001b[39m=\u001b[39m MultiprocessingPoolExecutor(pool)\n\u001b[1;32m---> 89\u001b[0m results \u001b[39m=\u001b[39m get_async(\n\u001b[0;32m     90\u001b[0m     pool\u001b[39m.\u001b[39msubmit,\n\u001b[0;32m     91\u001b[0m     pool\u001b[39m.\u001b[39m_max_workers,\n\u001b[0;32m     92\u001b[0m     dsk,\n\u001b[0;32m     93\u001b[0m     keys,\n\u001b[0;32m     94\u001b[0m     cache\u001b[39m=\u001b[39mcache,\n\u001b[0;32m     95\u001b[0m     get_id\u001b[39m=\u001b[39m_thread_get_id,\n\u001b[0;32m     96\u001b[0m     pack_exception\u001b[39m=\u001b[39mpack_exception,\n\u001b[0;32m     97\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m     98\u001b[0m )\n\u001b[0;32m    100\u001b[0m \u001b[39m# Cleanup pools associated to dead threads\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[39mwith\u001b[39;00m pools_lock:\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\dask\\local.py:511\u001b[0m, in \u001b[0;36mget_async\u001b[1;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[0;32m    509\u001b[0m         _execute_task(task, data)  \u001b[39m# Re-execute locally\u001b[39;00m\n\u001b[0;32m    510\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 511\u001b[0m         raise_exception(exc, tb)\n\u001b[0;32m    512\u001b[0m res, worker_id \u001b[39m=\u001b[39m loads(res_info)\n\u001b[0;32m    513\u001b[0m state[\u001b[39m\"\u001b[39m\u001b[39mcache\u001b[39m\u001b[39m\"\u001b[39m][key] \u001b[39m=\u001b[39m res\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\dask\\local.py:319\u001b[0m, in \u001b[0;36mreraise\u001b[1;34m(exc, tb)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[39mif\u001b[39;00m exc\u001b[39m.\u001b[39m__traceback__ \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m tb:\n\u001b[0;32m    318\u001b[0m     \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m--> 319\u001b[0m \u001b[39mraise\u001b[39;00m exc\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\dask\\local.py:224\u001b[0m, in \u001b[0;36mexecute_task\u001b[1;34m(key, task_info, dumps, loads, get_id, pack_exception)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    223\u001b[0m     task, data \u001b[39m=\u001b[39m loads(task_info)\n\u001b[1;32m--> 224\u001b[0m     result \u001b[39m=\u001b[39m _execute_task(task, data)\n\u001b[0;32m    225\u001b[0m     \u001b[39mid\u001b[39m \u001b[39m=\u001b[39m get_id()\n\u001b[0;32m    226\u001b[0m     result \u001b[39m=\u001b[39m dumps((result, \u001b[39mid\u001b[39m))\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\dask\\core.py:119\u001b[0m, in \u001b[0;36m_execute_task\u001b[1;34m(arg, cache, dsk)\u001b[0m\n\u001b[0;32m    115\u001b[0m     func, args \u001b[39m=\u001b[39m arg[\u001b[39m0\u001b[39m], arg[\u001b[39m1\u001b[39m:]\n\u001b[0;32m    116\u001b[0m     \u001b[39m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[39m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     \u001b[39m# operations in-place.\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m(_execute_task(a, cache) \u001b[39mfor\u001b[39;49;00m a \u001b[39min\u001b[39;49;00m args))\n\u001b[0;32m    120\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m ishashable(arg):\n\u001b[0;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m arg\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\dask\\optimization.py:990\u001b[0m, in \u001b[0;36mSubgraphCallable.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    988\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minkeys):\n\u001b[0;32m    989\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mExpected \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m args, got \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minkeys), \u001b[39mlen\u001b[39m(args)))\n\u001b[1;32m--> 990\u001b[0m \u001b[39mreturn\u001b[39;00m core\u001b[39m.\u001b[39;49mget(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdsk, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutkey, \u001b[39mdict\u001b[39;49m(\u001b[39mzip\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minkeys, args)))\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\dask\\core.py:149\u001b[0m, in \u001b[0;36mget\u001b[1;34m(dsk, out, cache)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m toposort(dsk):\n\u001b[0;32m    148\u001b[0m     task \u001b[39m=\u001b[39m dsk[key]\n\u001b[1;32m--> 149\u001b[0m     result \u001b[39m=\u001b[39m _execute_task(task, cache)\n\u001b[0;32m    150\u001b[0m     cache[key] \u001b[39m=\u001b[39m result\n\u001b[0;32m    151\u001b[0m result \u001b[39m=\u001b[39m _execute_task(out, cache)\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\dask\\core.py:119\u001b[0m, in \u001b[0;36m_execute_task\u001b[1;34m(arg, cache, dsk)\u001b[0m\n\u001b[0;32m    115\u001b[0m     func, args \u001b[39m=\u001b[39m arg[\u001b[39m0\u001b[39m], arg[\u001b[39m1\u001b[39m:]\n\u001b[0;32m    116\u001b[0m     \u001b[39m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[39m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     \u001b[39m# operations in-place.\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m(_execute_task(a, cache) \u001b[39mfor\u001b[39;49;00m a \u001b[39min\u001b[39;49;00m args))\n\u001b[0;32m    120\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m ishashable(arg):\n\u001b[0;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m arg\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\dask\\core.py:119\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    115\u001b[0m     func, args \u001b[39m=\u001b[39m arg[\u001b[39m0\u001b[39m], arg[\u001b[39m1\u001b[39m:]\n\u001b[0;32m    116\u001b[0m     \u001b[39m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[39m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     \u001b[39m# operations in-place.\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m(_execute_task(a, cache) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m args))\n\u001b[0;32m    120\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m ishashable(arg):\n\u001b[0;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m arg\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\dask\\core.py:119\u001b[0m, in \u001b[0;36m_execute_task\u001b[1;34m(arg, cache, dsk)\u001b[0m\n\u001b[0;32m    115\u001b[0m     func, args \u001b[39m=\u001b[39m arg[\u001b[39m0\u001b[39m], arg[\u001b[39m1\u001b[39m:]\n\u001b[0;32m    116\u001b[0m     \u001b[39m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[39m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     \u001b[39m# operations in-place.\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m(_execute_task(a, cache) \u001b[39mfor\u001b[39;49;00m a \u001b[39min\u001b[39;49;00m args))\n\u001b[0;32m    120\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m ishashable(arg):\n\u001b[0;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m arg\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\dask\\dataframe\\io\\csv.py:140\u001b[0m, in \u001b[0;36mCSVFunctionWrapper.__call__\u001b[1;34m(self, part)\u001b[0m\n\u001b[0;32m    137\u001b[0m         rest_kwargs[\u001b[39m\"\u001b[39m\u001b[39musecols\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m columns\n\u001b[0;32m    139\u001b[0m \u001b[39m# Call `pandas_read_text`\u001b[39;00m\n\u001b[1;32m--> 140\u001b[0m df \u001b[39m=\u001b[39m pandas_read_text(\n\u001b[0;32m    141\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreader,\n\u001b[0;32m    142\u001b[0m     block,\n\u001b[0;32m    143\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mheader,\n\u001b[0;32m    144\u001b[0m     rest_kwargs,\n\u001b[0;32m    145\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtypes,\n\u001b[0;32m    146\u001b[0m     columns,\n\u001b[0;32m    147\u001b[0m     write_header,\n\u001b[0;32m    148\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menforce,\n\u001b[0;32m    149\u001b[0m     path_info,\n\u001b[0;32m    150\u001b[0m )\n\u001b[0;32m    151\u001b[0m \u001b[39mif\u001b[39;00m project_after_read:\n\u001b[0;32m    152\u001b[0m     \u001b[39mreturn\u001b[39;00m df[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns]\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\dask\\dataframe\\io\\csv.py:193\u001b[0m, in \u001b[0;36mpandas_read_text\u001b[1;34m(reader, b, header, kwargs, dtypes, columns, write_header, enforce, path)\u001b[0m\n\u001b[0;32m    191\u001b[0m bio\u001b[39m.\u001b[39mwrite(b)\n\u001b[0;32m    192\u001b[0m bio\u001b[39m.\u001b[39mseek(\u001b[39m0\u001b[39m)\n\u001b[1;32m--> 193\u001b[0m df \u001b[39m=\u001b[39m reader(bio, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    194\u001b[0m \u001b[39mif\u001b[39;00m dtypes:\n\u001b[0;32m    195\u001b[0m     coerce_dtypes(df, dtypes)\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1753\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1750\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1752\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1753\u001b[0m     \u001b[39mreturn\u001b[39;00m mapping[engine](f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions)\n\u001b[0;32m   1754\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   1755\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:79\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     76\u001b[0m     kwds\u001b[39m.\u001b[39mpop(key, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m     78\u001b[0m kwds[\u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m ensure_dtype_objs(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m---> 79\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader \u001b[39m=\u001b[39m parsers\u001b[39m.\u001b[39mTextReader(src, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     81\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munnamed_cols \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader\u001b[39m.\u001b[39munnamed_cols\n\u001b[0;32m     83\u001b[0m \u001b[39m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:547\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:636\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:852\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:1973\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: out of memory"
     ]
    }
   ],
   "source": [
    "df['abs_diff_longitude'] = (df.dropoff_longitude - df.pickup_longitude).abs()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still out of memory error"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizing graph of operantion and operation in chunks\n",
    "\n",
    "The way Dask works involves two steps:\n",
    "\n",
    "1. First, you setup a computation, internally represented as a graph of operations.\n",
    "2. Then, you actually run the computation on that graph.\n",
    "\n",
    "Rough rules of thumb for chunksize:\n",
    "\n",
    "1. If you already created a prototype, which may not involve Dask at all, using a small subset of the data you intend to process, you’ll have a clear idea of what size of data can be processed easily for this workflow. You can use this knowledge to choose similar sized chunks in Dask.\n",
    "2. Some people have observed that chunk sizes below 1MB are almost always bad. Chunk size between 100MB and 1GB are generally good, going over 1 or 2GB means you have a really big dataset and/or a lot of memory available per core,\n",
    "3. Upper bound: Avoid too large task graphs. More than 10,000 or 100,000 chunks may start to perform poorly.\n",
    "4. Lower bound: To get the advantage of parallelization, you need the number of chunks to at least equal the number of worker cores available (or better, the number of worker cores times 2). Otherwise, some workers will stay idle.\n",
    "5. The time taken to compute each task should be much larger than the time needed to schedule the task. The Dask scheduler takes roughly 1 millisecond to coordinate a single task, so a good task computation time would be measured in seconds (not milliseconds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 49s\n",
      "Wall time: 2min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Load the data with Dask instead of Pandas.\n",
    "df = dd.read_csv(\n",
    "    'train.csv', \n",
    "    usecols=req_cols, \n",
    "    dtype=new_dtype,\n",
    "    blocksize=500 * 1024 * 1024, # 500MB chunks    \n",
    ")\n",
    "\n",
    "# Setup the calculation graph; unlike Pandas code,\n",
    "# no work is done at this point:\n",
    "def add_travel_vector_features(df):\n",
    "    df['abs_diff_longitude'] = (df.dropoff_longitude - df.pickup_longitude).abs()\n",
    "    df['abs_diff_latitude'] = (df.dropoff_latitude - df.pickup_latitude).abs()\n",
    "\n",
    "# Each degree of latitude or longitude equals approximately 111.11 km, so a distance of 2 degrees for the taxi would be unlikely.\n",
    "def calculation_graph1(df):\n",
    "    df.dropna(how='any')\n",
    "    add_travel_vector_features(df)\n",
    "    df = df[(df['abs_diff_latitude'] < 2) & ((df['abs_diff_longitude'] < 2) & ((df['fare_amount'] <= 500) & ((df['fare_amount'] >= 2.5) & (df['passenger_count'] <= 5))))]\n",
    "    return df\n",
    "\n",
    "df = calculation_graph1(df)\n",
    "\n",
    "# Actually run the computation, using 6 threads:\n",
    "df = df.compute(num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Processed_data/train_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m     df[\u001b[39m'\u001b[39m\u001b[39mpickup_datetime\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m dd\u001b[39m.\u001b[39mto_datetime(df[\u001b[39m'\u001b[39m\u001b[39mpickup_datetime\u001b[39m\u001b[39m'\u001b[39m], \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m     \u001b[39mreturn\u001b[39;00m df\n\u001b[1;32m----> 5\u001b[0m df \u001b[39m=\u001b[39m calculation_graph2(df)\n\u001b[0;32m      7\u001b[0m \u001b[39m# Actually run the computation, using 6 threads:\u001b[39;00m\n\u001b[0;32m      8\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mcompute(num_workers\u001b[39m=\u001b[39m\u001b[39m6\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m, in \u001b[0;36mcalculation_graph2\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcalculation_graph2\u001b[39m(df):\n\u001b[1;32m----> 2\u001b[0m     df[\u001b[39m'\u001b[39m\u001b[39mpickup_datetime\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m dd\u001b[39m.\u001b[39;49mto_datetime(df[\u001b[39m'\u001b[39;49m\u001b[39mpickup_datetime\u001b[39;49m\u001b[39m'\u001b[39;49m], \u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      3\u001b[0m     \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\dask\\dataframe\\core.py:8050\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, meta, **kwargs)\u001b[0m\n\u001b[0;32m   8041\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   8042\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe argument \u001b[39m\u001b[39m'\u001b[39m\u001b[39minfer_datetime_format\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is deprecated and will be removed in a future version. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   8043\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mA strict version of it is now the default, see \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   8046\u001b[0m         \u001b[39mUserWarning\u001b[39;00m,\n\u001b[0;32m   8047\u001b[0m     )\n\u001b[0;32m   8048\u001b[0m     kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39minfer_datetime_format\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 8050\u001b[0m \u001b[39mreturn\u001b[39;00m map_partitions(pd\u001b[39m.\u001b[39mto_datetime, arg, meta\u001b[39m=\u001b[39mmeta, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\dask\\dataframe\\core.py:6846\u001b[0m, in \u001b[0;36mmap_partitions\u001b[1;34m(func, meta, enforce_metadata, transform_divisions, align_dataframes, *args, **kwargs)\u001b[0m\n\u001b[0;32m   6844\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6845\u001b[0m     name \u001b[39m=\u001b[39m funcname(func)\n\u001b[1;32m-> 6846\u001b[0m     token \u001b[39m=\u001b[39m tokenize(func, meta, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   6847\u001b[0m name \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m{\u001b[39;00mtoken\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   6849\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataframe\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmulti\u001b[39;00m \u001b[39mimport\u001b[39;00m _maybe_align_partitions\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\dask\\base.py:930\u001b[0m, in \u001b[0;36mtokenize\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtokenize\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    922\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Deterministic token\u001b[39;00m\n\u001b[0;32m    923\u001b[0m \n\u001b[0;32m    924\u001b[0m \u001b[39m    >>> tokenize([1, 2, '3'])\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[39m    True\u001b[39;00m\n\u001b[0;32m    929\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 930\u001b[0m     hasher \u001b[39m=\u001b[39m _md5(\u001b[39mstr\u001b[39m(\u001b[39mtuple\u001b[39;49m(\u001b[39mmap\u001b[39;49m(normalize_token, args)))\u001b[39m.\u001b[39mencode())\n\u001b[0;32m    931\u001b[0m     \u001b[39mif\u001b[39;00m kwargs:\n\u001b[0;32m    932\u001b[0m         hasher\u001b[39m.\u001b[39mupdate(\u001b[39mstr\u001b[39m(normalize_token(kwargs))\u001b[39m.\u001b[39mencode())\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\dask\\utils.py:642\u001b[0m, in \u001b[0;36mDispatch.__call__\u001b[1;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    639\u001b[0m \u001b[39mCall the corresponding method based on type of argument.\u001b[39;00m\n\u001b[0;32m    640\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    641\u001b[0m meth \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch(\u001b[39mtype\u001b[39m(arg))\n\u001b[1;32m--> 642\u001b[0m \u001b[39mreturn\u001b[39;00m meth(arg, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\dask\\base.py:1138\u001b[0m, in \u001b[0;36mregister_pandas.<locals>.normalize_series\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m   1133\u001b[0m \u001b[39m@normalize_token\u001b[39m\u001b[39m.\u001b[39mregister(pd\u001b[39m.\u001b[39mSeries)\n\u001b[0;32m   1134\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnormalize_series\u001b[39m(s):\n\u001b[0;32m   1135\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[0;32m   1136\u001b[0m         s\u001b[39m.\u001b[39mname,\n\u001b[0;32m   1137\u001b[0m         s\u001b[39m.\u001b[39mdtype,\n\u001b[1;32m-> 1138\u001b[0m         normalize_token(s\u001b[39m.\u001b[39;49m_values),\n\u001b[0;32m   1139\u001b[0m         normalize_token(s\u001b[39m.\u001b[39mindex),\n\u001b[0;32m   1140\u001b[0m     ]\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\dask\\utils.py:642\u001b[0m, in \u001b[0;36mDispatch.__call__\u001b[1;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    639\u001b[0m \u001b[39mCall the corresponding method based on type of argument.\u001b[39;00m\n\u001b[0;32m    640\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    641\u001b[0m meth \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch(\u001b[39mtype\u001b[39m(arg))\n\u001b[1;32m--> 642\u001b[0m \u001b[39mreturn\u001b[39;00m meth(arg, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\dask\\base.py:1152\u001b[0m, in \u001b[0;36mregister_pandas.<locals>.normalize_extension_array\u001b[1;34m(arr)\u001b[0m\n\u001b[0;32m   1148\u001b[0m \u001b[39m@normalize_token\u001b[39m\u001b[39m.\u001b[39mregister(pd\u001b[39m.\u001b[39mapi\u001b[39m.\u001b[39mextensions\u001b[39m.\u001b[39mExtensionArray)\n\u001b[0;32m   1149\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnormalize_extension_array\u001b[39m(arr):\n\u001b[0;32m   1150\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m normalize_token(np\u001b[39m.\u001b[39;49masarray(arr))\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\dask\\utils.py:642\u001b[0m, in \u001b[0;36mDispatch.__call__\u001b[1;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    639\u001b[0m \u001b[39mCall the corresponding method based on type of argument.\u001b[39;00m\n\u001b[0;32m    640\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    641\u001b[0m meth \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch(\u001b[39mtype\u001b[39m(arg))\n\u001b[1;32m--> 642\u001b[0m \u001b[39mreturn\u001b[39;00m meth(arg, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\dask\\base.py:1196\u001b[0m, in \u001b[0;36mregister_numpy.<locals>.normalize_array\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1192\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1193\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1194\u001b[0m         \u001b[39m# string fast-path\u001b[39;00m\n\u001b[0;32m   1195\u001b[0m         data \u001b[39m=\u001b[39m hash_buffer_hex(\n\u001b[1;32m-> 1196\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(x\u001b[39m.\u001b[39;49mflat)\u001b[39m.\u001b[39mencode(\n\u001b[0;32m   1197\u001b[0m                 encoding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m, errors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msurrogatepass\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1198\u001b[0m             )\n\u001b[0;32m   1199\u001b[0m         )\n\u001b[0;32m   1200\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mUnicodeDecodeError\u001b[39;00m:\n\u001b[0;32m   1201\u001b[0m         \u001b[39m# bytes fast-path\u001b[39;00m\n\u001b[0;32m   1202\u001b[0m         data \u001b[39m=\u001b[39m hash_buffer_hex(\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(x\u001b[39m.\u001b[39mflat))\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def calculation_graph2(df):\n",
    "    df['pickup_datetime'] = dd.to_datetime(df['pickup_datetime'], format=True)\n",
    "    return df\n",
    "\n",
    "df = calculation_graph2(df)\n",
    "\n",
    "# Actually run the computation, using 6 threads:\n",
    "df = df.compute(num_workers=6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function dd.to_datetime stills isn't optmizes enough for running on the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abs_diff_longitude</th>\n",
       "      <th>abs_diff_latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50124</th>\n",
       "      <td>1.372154</td>\n",
       "      <td>1.946140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75161</th>\n",
       "      <td>1.704330</td>\n",
       "      <td>1.934723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81217</th>\n",
       "      <td>0.002403</td>\n",
       "      <td>1.924252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56814</th>\n",
       "      <td>1.483332</td>\n",
       "      <td>1.904047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116669</th>\n",
       "      <td>0.226624</td>\n",
       "      <td>1.888096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13868</th>\n",
       "      <td>0.216530</td>\n",
       "      <td>1.887989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88742</th>\n",
       "      <td>1.185425</td>\n",
       "      <td>1.886124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115628</th>\n",
       "      <td>0.131516</td>\n",
       "      <td>1.881638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90896</th>\n",
       "      <td>0.003975</td>\n",
       "      <td>1.880322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77667</th>\n",
       "      <td>0.007141</td>\n",
       "      <td>1.876225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        abs_diff_longitude  abs_diff_latitude\n",
       "50124             1.372154           1.946140\n",
       "75161             1.704330           1.934723\n",
       "81217             0.002403           1.924252\n",
       "56814             1.483332           1.904047\n",
       "116669            0.226624           1.888096\n",
       "13868             0.216530           1.887989\n",
       "88742             1.185425           1.886124\n",
       "115628            0.131516           1.881638\n",
       "90896             0.003975           1.880322\n",
       "77667             0.007141           1.876225"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['abs_diff_longitude', 'abs_diff_latitude']].sort_values('abs_diff_latitude', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-06-15 17:26:21 UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-05 16:52:16 UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-08-18 00:35:00 UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-04-21 04:30:42 UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-03-09 07:51:00 UTC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pickup_datetime\n",
       "0  2009-06-15 17:26:21 UTC\n",
       "1  2010-01-05 16:52:16 UTC\n",
       "2  2011-08-18 00:35:00 UTC\n",
       "3  2012-04-21 04:30:42 UTC\n",
       "4  2010-03-09 07:51:00 UTC"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The column pickup_datetime is in date format, but Pandas/Dask still needs to recognize that\n",
    "df[['pickup_datetime']][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[\u001b[39m'\u001b[39;49m\u001b[39mpickup_datetime\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m=\u001b[39m dd\u001b[39m.\u001b[39mto_datetime(df[\u001b[39m'\u001b[39m\u001b[39mpickup_datetime\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\pandas\\core\\frame.py:3980\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3977\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   3978\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3979\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[1;32m-> 3980\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\pandas\\core\\frame.py:4174\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4164\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_item\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   4165\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4166\u001b[0m \u001b[39m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   4167\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4172\u001b[0m \u001b[39m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   4173\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4174\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sanitize_column(value)\n\u001b[0;32m   4176\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   4177\u001b[0m         key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[0;32m   4178\u001b[0m         \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   4179\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[0;32m   4180\u001b[0m     ):\n\u001b[0;32m   4181\u001b[0m         \u001b[39m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   4182\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\pandas\\core\\frame.py:4915\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4912\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n\u001b[0;32m   4914\u001b[0m \u001b[39mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m-> 4915\u001b[0m     com\u001b[39m.\u001b[39;49mrequire_length_match(value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex)\n\u001b[0;32m   4916\u001b[0m \u001b[39mreturn\u001b[39;00m sanitize_array(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_2d\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\pandas\\core\\common.py:570\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequire_length_match\u001b[39m(data, index: Index) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    567\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    568\u001b[0m \u001b[39m    Check the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    569\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 570\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39;49m(data) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[0;32m    571\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    572\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mLength of values \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    573\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    574\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mdoes not match length of index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    575\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    576\u001b[0m         )\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\dask\\dataframe\\core.py:841\u001b[0m, in \u001b[0;36m_Frame.__len__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__len__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 841\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction(\n\u001b[0;32m    842\u001b[0m         \u001b[39mlen\u001b[39;49m, np\u001b[39m.\u001b[39;49msum, token\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mlen\u001b[39;49m\u001b[39m\"\u001b[39;49m, meta\u001b[39m=\u001b[39;49m\u001b[39mint\u001b[39;49m, split_every\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[0;32m    843\u001b[0m     )\u001b[39m.\u001b[39;49mcompute()\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\dask\\base.py:314\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    291\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \n\u001b[0;32m    293\u001b[0m \u001b[39m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[39m    dask.base.compute\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 314\u001b[0m     (result,) \u001b[39m=\u001b[39m compute(\u001b[39mself\u001b[39m, traverse\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    315\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\dask\\base.py:599\u001b[0m, in \u001b[0;36mcompute\u001b[1;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[0;32m    596\u001b[0m     keys\u001b[39m.\u001b[39mappend(x\u001b[39m.\u001b[39m__dask_keys__())\n\u001b[0;32m    597\u001b[0m     postcomputes\u001b[39m.\u001b[39mappend(x\u001b[39m.\u001b[39m__dask_postcompute__())\n\u001b[1;32m--> 599\u001b[0m results \u001b[39m=\u001b[39m schedule(dsk, keys, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    600\u001b[0m \u001b[39mreturn\u001b[39;00m repack([f(r, \u001b[39m*\u001b[39ma) \u001b[39mfor\u001b[39;00m r, (f, a) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\dask\\threaded.py:89\u001b[0m, in \u001b[0;36mget\u001b[1;34m(dsk, keys, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(pool, multiprocessing\u001b[39m.\u001b[39mpool\u001b[39m.\u001b[39mPool):\n\u001b[0;32m     87\u001b[0m         pool \u001b[39m=\u001b[39m MultiprocessingPoolExecutor(pool)\n\u001b[1;32m---> 89\u001b[0m results \u001b[39m=\u001b[39m get_async(\n\u001b[0;32m     90\u001b[0m     pool\u001b[39m.\u001b[39msubmit,\n\u001b[0;32m     91\u001b[0m     pool\u001b[39m.\u001b[39m_max_workers,\n\u001b[0;32m     92\u001b[0m     dsk,\n\u001b[0;32m     93\u001b[0m     keys,\n\u001b[0;32m     94\u001b[0m     cache\u001b[39m=\u001b[39mcache,\n\u001b[0;32m     95\u001b[0m     get_id\u001b[39m=\u001b[39m_thread_get_id,\n\u001b[0;32m     96\u001b[0m     pack_exception\u001b[39m=\u001b[39mpack_exception,\n\u001b[0;32m     97\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m     98\u001b[0m )\n\u001b[0;32m    100\u001b[0m \u001b[39m# Cleanup pools associated to dead threads\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[39mwith\u001b[39;00m pools_lock:\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\dask\\local.py:500\u001b[0m, in \u001b[0;36mget_async\u001b[1;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[0;32m    498\u001b[0m \u001b[39mwhile\u001b[39;00m state[\u001b[39m\"\u001b[39m\u001b[39mwaiting\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mor\u001b[39;00m state[\u001b[39m\"\u001b[39m\u001b[39mready\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mor\u001b[39;00m state[\u001b[39m\"\u001b[39m\u001b[39mrunning\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    499\u001b[0m     fire_tasks(chunksize)\n\u001b[1;32m--> 500\u001b[0m     \u001b[39mfor\u001b[39;00m key, res_info, failed \u001b[39min\u001b[39;00m queue_get(queue)\u001b[39m.\u001b[39mresult():\n\u001b[0;32m    501\u001b[0m         \u001b[39mif\u001b[39;00m failed:\n\u001b[0;32m    502\u001b[0m             exc, tb \u001b[39m=\u001b[39m loads(res_info)\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\site-packages\\dask\\local.py:130\u001b[0m, in \u001b[0;36mqueue_get\u001b[1;34m(q)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 130\u001b[0m         \u001b[39mreturn\u001b[39;00m q\u001b[39m.\u001b[39;49mget(block\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, timeout\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m)\n\u001b[0;32m    131\u001b[0m     \u001b[39mexcept\u001b[39;00m Empty:\n\u001b[0;32m    132\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[39mif\u001b[39;00m remaining \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m:\n\u001b[0;32m    179\u001b[0m             \u001b[39mraise\u001b[39;00m Empty\n\u001b[1;32m--> 180\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnot_empty\u001b[39m.\u001b[39;49mwait(remaining)\n\u001b[0;32m    181\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get()\n\u001b[0;32m    182\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnot_full\u001b[39m.\u001b[39mnotify()\n",
      "File \u001b[1;32md:\\User\\Adriel\\Anaconda\\Installed\\envs\\kaggle\\lib\\threading.py:316\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    315\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 316\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39;49macquire(\u001b[39mTrue\u001b[39;49;00m, timeout)\n\u001b[0;32m    317\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    318\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39macquire(\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df['pickup_datetime'] = dd.to_datetime(df['pickup_datetime'], format='%Y-%m-%d %H:%M:%S %Z')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
